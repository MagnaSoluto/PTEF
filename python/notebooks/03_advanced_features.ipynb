{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PTEF - Funcionalidades Avançadas\n",
        "\n",
        "Este notebook demonstra as funcionalidades avançadas do PTEF implementadas conforme o artigo:\n",
        "\n",
        "## Funcionalidades Demonstradas\n",
        "- **Contexto Condicional**: Duração das sílabas baseada em contexto\n",
        "- **Bootstrap**: Intervalos de confiança robustos\n",
        "- **Validação**: Comparação com TTS e falantes humanos\n",
        "- **Análise de Sensibilidade**: Variação de parâmetros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join('..', 'src'))\n",
        "\n",
        "import ptef\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ptef import (\n",
        "    estimate, PTEFParams, ContextModel, BootstrapConfig,\n",
        "    bootstrap_estimate, run_full_validation, ValidationConfig\n",
        ")\n",
        "\n",
        "# Configurar matplotlib\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Contexto Condicional\n",
        "\n",
        "Demonstração do modelo de duração condicionada ao contexto conforme o artigo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar modelo de contexto personalizado\n",
        "context_model = ContextModel(\n",
        "    beta_position=0.001,      # Efeito da posição no grupo\n",
        "    beta_complexity=0.05,     # Efeito da complexidade recente\n",
        "    beta_long_words=0.02,     # Efeito de palavras longas\n",
        "    beta_connective=-0.1,     # Conectivos são mais rápidos\n",
        "    beta_boundary=0.15,       # Fronteiras prosódicas são mais lentas\n",
        "    beta_stress=0.1,          # Sílabas tônicas são mais lentas\n",
        "    mu_base=0.15,             # Duração base\n",
        "    sigma=0.3,                # Variabilidade\n",
        "    fatigue_coeff=0.0001      # Coeficiente de fadiga\n",
        ")\n",
        "\n",
        "# Parâmetros PTEF com contexto\n",
        "params_with_context = PTEFParams(\n",
        "    context_model=context_model,\n",
        "    use_context=True\n",
        ")\n",
        "\n",
        "# Comparar estimações com e sem contexto\n",
        "N = 1000\n",
        "\n",
        "# Sem contexto (método padrão)\n",
        "result_no_context = estimate(N, return_ci=True)\n",
        "\n",
        "# Com contexto\n",
        "result_with_context = estimate(N, params=params_with_context, return_ci=True)\n",
        "\n",
        "print(\"=== Comparação: Sem vs Com Contexto ===\")\n",
        "print(f\"Sem contexto: {result_no_context['mean']:.3f}s\")\n",
        "print(f\"Com contexto: {result_with_context['mean']:.3f}s\")\n",
        "print(f\"Diferença: {result_with_context['mean'] - result_no_context['mean']:.3f}s\")\n",
        "print(f\"Percentual: {((result_with_context['mean'] / result_no_context['mean']) - 1) * 100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Bootstrap para Intervalos de Confiança\n",
        "\n",
        "Demonstração do método bootstrap para estimar intervalos de confiança robustos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuração do bootstrap\n",
        "bootstrap_config = BootstrapConfig(\n",
        "    n_bootstrap=1000,           # 1000 amostras bootstrap\n",
        "    confidence_level=0.95,      # IC 95%\n",
        "    method=\"percentile\",        # Método percentil\n",
        "    random_seed=42              # Semente para reprodutibilidade\n",
        ")\n",
        "\n",
        "# Parâmetros PTEF com bootstrap\n",
        "params_with_bootstrap = PTEFParams(\n",
        "    bootstrap_config=bootstrap_config,\n",
        "    use_bootstrap=True\n",
        ")\n",
        "\n",
        "# Comparar métodos de CI\n",
        "N = 1000\n",
        "\n",
        "# Método padrão (aproximação normal)\n",
        "result_normal = estimate(N, return_ci=True)\n",
        "\n",
        "# Método bootstrap\n",
        "result_bootstrap = estimate(N, params=params_with_bootstrap, return_ci=True)\n",
        "\n",
        "print(\"=== Comparação: CI Normal vs Bootstrap ===\")\n",
        "print(f\"Método normal:\")\n",
        "print(f\"  Média: {result_normal['mean']:.3f}s\")\n",
        "print(f\"  IC95%: [{result_normal['ci95']['lower']:.3f}, {result_normal['ci95']['upper']:.3f}]\")\n",
        "print(f\"  Largura: {result_normal['ci95']['upper'] - result_normal['ci95']['lower']:.3f}s\")\n",
        "\n",
        "print(f\"\\nMétodo bootstrap:\")\n",
        "print(f\"  Média: {result_bootstrap['mean']:.3f}s\")\n",
        "print(f\"  IC95%: [{result_bootstrap['ci95']['lower']:.3f}, {result_bootstrap['ci95']['upper']:.3f}]\")\n",
        "print(f\"  Largura: {result_bootstrap['ci95']['upper'] - result_bootstrap['ci95']['lower']:.3f}s\")\n",
        "print(f\"  Método: {result_bootstrap['ci95']['method']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Análise de Sensibilidade\n",
        "\n",
        "Demonstração da análise de sensibilidade dos parâmetros conforme o artigo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análise de sensibilidade dos parâmetros\n",
        "from ptef.bootstrap import bootstrap_sensitivity_analysis\n",
        "\n",
        "# Definir faixas de parâmetros para testar\n",
        "parameter_ranges = {\n",
        "    \"mu_base\": [0.10, 0.15, 0.20, 0.25],      # Duração base\n",
        "    \"sigma\": [0.2, 0.3, 0.4, 0.5],            # Variabilidade\n",
        "    \"fatigue_coeff\": [0.00005, 0.0001, 0.0002, 0.0005]  # Coeficiente de fadiga\n",
        "}\n",
        "\n",
        "# Executar análise de sensibilidade\n",
        "sensitivity_results = bootstrap_sensitivity_analysis(\n",
        "    N=1000,\n",
        "    parameter_ranges=parameter_ranges,\n",
        "    config=bootstrap_config\n",
        ")\n",
        "\n",
        "# Visualizar resultados\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for i, (param, values) in enumerate(parameter_ranges.items()):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # Extrair dados para o parâmetro\n",
        "    param_data = sensitivity_results[param]\n",
        "    means = [data[\"mean\"] for data in param_data.values()]\n",
        "    \n",
        "    # Plotar\n",
        "    ax.plot(values, means, 'o-', linewidth=2, markersize=8)\n",
        "    ax.set_xlabel(f'{param}')\n",
        "    ax.set_ylabel('Duração Média (s)')\n",
        "    ax.set_title(f'Sensibilidade: {param}')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mostrar tabela de resultados\n",
        "print(\"=== Análise de Sensibilidade ===\")\n",
        "for param, values in parameter_ranges.items():\n",
        "    print(f\"\\n{param}:\")\n",
        "    for value, data in sensitivity_results[param].items():\n",
        "        print(f\"  {value}: {data['mean']:.3f}s (IC: [{data['ci_lower']:.3f}, {data['ci_upper']:.3f}])\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Validação com TTS e Falantes Humanos\n",
        "\n",
        "Demonstração do sistema de validação conforme o artigo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuração de validação\n",
        "validation_config = ValidationConfig(\n",
        "    tts_engines=[\"espeak\", \"festival\"],  # Motores TTS disponíveis\n",
        "    num_speakers=5,                      # Número de falantes simulados\n",
        "    accents=[\"southeast\", \"northeast\", \"south\"],  # Sotaques\n",
        "    small_range=(1, 50),                 # Faixa pequena para teste\n",
        "    medium_range=(1, 200),               # Faixa média\n",
        "    large_range=(1, 1000),               # Faixa grande\n",
        "    confidence_level=0.95,               # Nível de confiança\n",
        "    bootstrap_samples=500,               # Amostras bootstrap\n",
        "    rmse_threshold=0.15                  # Limite de RMSE aceitável\n",
        ")\n",
        "\n",
        "# Executar validação completa\n",
        "print(\"Executando validação completa...\")\n",
        "print(\"(Nota: Esta é uma simulação - em produção usaria TTS e falantes reais)\")\n",
        "\n",
        "# Números para validar\n",
        "test_numbers = list(range(1, 51))  # 1 a 50 para teste rápido\n",
        "\n",
        "# Executar validação\n",
        "validation_report = run_full_validation(test_numbers, validation_config)\n",
        "\n",
        "# Mostrar relatório\n",
        "print(\"\\n=== Relatório de Validação ===\")\n",
        "print(f\"TTS Analysis: {len(validation_report['tts_analysis'])} engines testados\")\n",
        "print(f\"Human Analysis: {len(validation_report['human_analysis'])} falantes testados\")\n",
        "print(f\"Ablation Analysis: {len(validation_report['ablation_analysis'])} métodos comparados\")\n",
        "\n",
        "# Mostrar recomendações\n",
        "if validation_report['recommendations']:\n",
        "    print(\"\\nRecomendações:\")\n",
        "    for i, rec in enumerate(validation_report['recommendations'], 1):\n",
        "        print(f\"  {i}. {rec}\")\n",
        "else:\n",
        "    print(\"\\nNenhuma recomendação específica - validação passou nos critérios!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comparação de Métodos Bootstrap\n",
        "\n",
        "Demonstração da comparação entre diferentes métodos bootstrap.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar diferentes métodos bootstrap\n",
        "from ptef.bootstrap import compare_bootstrap_methods\n",
        "\n",
        "# Métodos para comparar\n",
        "bootstrap_methods = [\"percentile\", \"bca\", \"studentized\"]\n",
        "\n",
        "# Executar comparação\n",
        "comparison_results = compare_bootstrap_methods(\n",
        "    N=1000,\n",
        "    methods=bootstrap_methods,\n",
        "    config=bootstrap_config\n",
        ")\n",
        "\n",
        "# Visualizar comparação\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gráfico 1: Médias\n",
        "methods = list(comparison_results.keys())\n",
        "means = [comparison_results[method][\"mean\"] for method in methods]\n",
        "ci_lowers = [comparison_results[method][\"ci_lower\"] for method in methods]\n",
        "ci_uppers = [comparison_results[method][\"ci_upper\"] for method in methods]\n",
        "\n",
        "x_pos = range(len(methods))\n",
        "ax1.bar(x_pos, means, yerr=[np.array(means) - np.array(ci_lowers), \n",
        "                           np.array(ci_uppers) - np.array(means)], \n",
        "        capsize=5, alpha=0.7)\n",
        "ax1.set_xlabel('Método Bootstrap')\n",
        "ax1.set_ylabel('Duração Média (s)')\n",
        "ax1.set_title('Comparação de Médias por Método')\n",
        "ax1.set_xticks(x_pos)\n",
        "ax1.set_xticklabels(methods, rotation=45)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Largura dos intervalos\n",
        "ci_widths = [comparison_results[method][\"ci_width\"] for method in methods]\n",
        "ax2.bar(x_pos, ci_widths, alpha=0.7, color='orange')\n",
        "ax2.set_xlabel('Método Bootstrap')\n",
        "ax2.set_ylabel('Largura do IC95% (s)')\n",
        "ax2.set_title('Largura dos Intervalos de Confiança')\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(methods, rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Tabela de resultados\n",
        "print(\"=== Comparação de Métodos Bootstrap ===\")\n",
        "print(f\"{'Método':<12} {'Média (s)':<10} {'IC95% Inferior':<15} {'IC95% Superior':<15} {'Largura (s)':<12}\")\n",
        "print(\"-\" * 80)\n",
        "for method in methods:\n",
        "    result = comparison_results[method]\n",
        "    print(f\"{method:<12} {result['mean']:<10.3f} {result['ci_lower']:<15.3f} {result['ci_upper']:<15.3f} {result['ci_width']:<12.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Resumo e Conclusões\n",
        "\n",
        "Este notebook demonstrou as funcionalidades avançadas do PTEF implementadas conforme o artigo:\n",
        "\n",
        "### ✅ **Funcionalidades Implementadas**\n",
        "\n",
        "1. **Contexto Condicional**: Duração das sílabas baseada em características contextuais\n",
        "2. **Bootstrap**: Intervalos de confiança robustos via amostragem\n",
        "3. **Validação**: Sistema de validação com TTS e falantes humanos\n",
        "4. **Análise de Sensibilidade**: Avaliação da robustez dos parâmetros\n",
        "5. **Comparação de Métodos**: Diferentes abordagens bootstrap\n",
        "\n",
        "### 📊 **Conformidade com o Artigo**\n",
        "\n",
        "- ✅ Formulação matemática completa\n",
        "- ✅ Microduração lognormal condicionada\n",
        "- ✅ Pausas prosódicas modeladas\n",
        "- ✅ Algoritmo O(log N) implementado\n",
        "- ✅ Gramática R1 fiel ao artigo\n",
        "- ✅ Bootstrap para IC robustos\n",
        "- ✅ Validação com TTS/humano\n",
        "- ✅ Análise de sensibilidade\n",
        "\n",
        "### 🚀 **Próximos Passos**\n",
        "\n",
        "1. **Validação Real**: Integrar com TTS engines reais\n",
        "2. **Dados Humanos**: Coletar dados de falantes reais\n",
        "3. **Otimização**: Melhorar performance para N muito grande\n",
        "4. **Interface Web**: Criar interface web para demonstração\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
